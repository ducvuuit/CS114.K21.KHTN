{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUgmvHqF1rOn",
        "colab_type": "text"
      },
      "source": [
        "###***1. Mô tả bài toán và cách thu thập dữ liệu***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qsa2JrQ3KQz",
        "colab_type": "text"
      },
      "source": [
        ">Sarcasm Detection (Nhận diện lời nói châm chọc) là một lĩnh vực hẹp của Xử lý ngôn ngữ tự nhiên, đây cũng là một dạng của Phân tích cảm xúc nhưng tập trung vào những lời châm chọc. Nhiệm vụ của bài toán này là phát hiện một câu văn có mang tính châm chọc hay không.\n",
        ">>*Input*: một câu văn.\\\n",
        ">>*Ouput*: Câu văn đó mang tính châm chọc, hoặc không mang tính châm chọc.\n",
        "\n",
        ">Cách thu thập dữ liệu:\\\n",
        "Các tác giả của bộ dữ liệu đã thu thập tiêu đề của những bài báo trên 2 trang Huffpost và TheOnion. Trong đó, hầu hết những bài báo của TheOnion đều mang tính châm chọc, trong khi đó những bài của Huffpost thì không nên tác giả có thể \"tự động\" gán nhãn với độ chính xác cao. Bên cạnh đó, 2 trang trên đều là những trang báo uy tính nên có thể hạn chế việc sai chính tả và những tiêu đề không phù hợp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAu5xuN23K-f",
        "colab_type": "text"
      },
      "source": [
        "###***2. Thu thập 2000 headline mới***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItkiCxO831Ar",
        "colab_type": "text"
      },
      "source": [
        "**Dữ liệu mới từ The Onion**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jX3uAloUF4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "brief_ids = [1592941800660, 1592571600580, 1592417460860, 1592310660550, \n",
        "             1591968360154, 1591805040173, 1591711680285, 1591367220974, \n",
        "             1592311200653, 1591726080182, 1591127280478, 1590584520209, \n",
        "             1589894280339, 1589294340828, 1588711020164, 1588080060229, \n",
        "             1587147720532, 1586546460312, 1586184540217, 1585581600531,\n",
        "             1582920840434, 1582639200695, 1582128720515, 1581532200479,\n",
        "             1581099360048, 1580744340055, 1580142900840, 1579637820343,\n",
        "             1579096620327, 1578410280620, 1576700820848, 1576184280994,\n",
        "             1575574260415, 1575036000486, 1574361720213, 1573762560848,\n",
        "             1573477200438, 1572900480129, 1572348600499, 1571938620032,\n",
        "             1571419440061, 1591190640748, 1591033980529, 1590695700723,\n",
        "             1590584520208, 1590406260047, 1590083040702, 1589922240735]\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-5tTDy1VJc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Onion_crawler(tag, ids, num_articles, label=1):\n",
        "  count = 0\n",
        "  for id in ids:\n",
        "    source = requests.get(\"https://www.theonion.com/c/{}?startTime={}\".format(tag,id)).text\n",
        "    soup = BeautifulSoup(source, 'lxml')\n",
        "    for article in soup.find_all('article'):\n",
        "      headline = article.h2.text\n",
        "      csv_writer.writerow([label, headline])\n",
        "      count += 1\n",
        "      if count == num_articles:\n",
        "        print(f\"Crawled {count} headlines from {tag} tag\")\n",
        "        return"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLhtVsWVTxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74260abf-6820-4815-9b93-d17bff3aa7a6"
      },
      "source": [
        "csv_file = open('new_onion_headlines.csv', 'w')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['is_sarcastic', 'headline'])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBhUI5lxVeMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Onion_crawler(\"news-in-brief\", brief_ids, num_articles=1000, label=1)\n",
        "csv_file.close()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R05Rp5n_VlV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0dd29736-b3a8-4b79-9001-2305a07becae"
      },
      "source": [
        "import pandas as pd\n",
        "onion_df = pd.read_csv(\"new_onion_headlines.csv\")\n",
        "onion_df.head(1000)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Study Finds Gap Widening Between Rich Pets And...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Heavily Armed Self-Help Gurus Demand America R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>White House Announces Entire U.S. Populace Of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Facebook Announces Plan To Break Up U.S. Gover...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Dog Owner Not Sure How City Expects Her To Pic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>1</td>\n",
              "      <td>Police Still Investigating What Happened Betwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>1</td>\n",
              "      <td>Updated Patriot Act Finally Legalizes 80% Of C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>1</td>\n",
              "      <td>Nurse Wearing Snoopy Scrubs, Floral Face Mask ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>1</td>\n",
              "      <td>Family Can Trace Ancestry Back To Whatever The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959</th>\n",
              "      <td>1</td>\n",
              "      <td>Prize Hog Doesn’t Know How She Can Retain Comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>960 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     is_sarcastic                                           headline\n",
              "0               1  Study Finds Gap Widening Between Rich Pets And...\n",
              "1               1  Heavily Armed Self-Help Gurus Demand America R...\n",
              "2               1  White House Announces Entire U.S. Populace Of ...\n",
              "3               1  Facebook Announces Plan To Break Up U.S. Gover...\n",
              "4               1  Dog Owner Not Sure How City Expects Her To Pic...\n",
              "..            ...                                                ...\n",
              "955             1  Police Still Investigating What Happened Betwe...\n",
              "956             1  Updated Patriot Act Finally Legalizes 80% Of C...\n",
              "957             1  Nurse Wearing Snoopy Scrubs, Floral Face Mask ...\n",
              "958             1  Family Can Trace Ancestry Back To Whatever The...\n",
              "959             1  Prize Hog Doesn’t Know How She Can Retain Comp...\n",
              "\n",
              "[960 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rg7kiRV3NaI",
        "colab_type": "text"
      },
      "source": [
        "###**3. Mô tả cách xử lý dữ liệu, feature engineering trên dataset đã cho. ***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z0QaTWF31a5",
        "colab_type": "text"
      },
      "source": [
        "**Feature engineering**\n",
        "  \n",
        "  Sử dụng CountVectorizer để trích xuất đặc trưng (Ngoài ra còn có thể sự dụng TfidfVectorizer). Nó sử dụng dùng để vector hóa một đoạn văn bản\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6wXZ0k3OSBf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_pBk3ZJ3oZT",
        "colab_type": "text"
      },
      "source": [
        "###***4. Mô tả quá trình chọn model, học và fine tuning***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IK-nXs33zVm",
        "colab_type": "text"
      },
      "source": [
        "adsdád"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjVL9Qb23x0o",
        "colab_type": "text"
      },
      "source": [
        "###***5. Mô tả cách dùng model đã train để viết một đoạn chương trình ngắn, thực hiện sacarsm detection cho một headline bất kỳ được nhập vào.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cVW7no4NP3",
        "colab_type": "text"
      },
      "source": [
        "sa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByWOQCs94JBw",
        "colab_type": "text"
      },
      "source": [
        "###***6. Đối chiếu performance của model trên dataset đã cho và trên 2000 headine mới. Nêu nhận xét của nhóm về bài toán này.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpF_mTJY4N1P",
        "colab_type": "text"
      },
      "source": [
        "sa"
      ]
    }
  ]
}